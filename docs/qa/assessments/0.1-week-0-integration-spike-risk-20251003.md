# Risk Profile: Story 0.1 - Week 0 Integration Spike

**Date:** 2025-10-03
**Reviewer:** Quinn (Test Architect)
**Story:** Week 0 Integration Spike
**Epic:** 0 (Foundation)

---

## Executive Summary

- **Total Risks Identified:** 14
- **Critical Risks:** 1
- **High Risks:** 3
- **Medium Risks:** 6
- **Low Risks:** 4
- **Overall Risk Score:** 12/100 (High Risk - Requires Active Mitigation)

**Key Finding:** One critical risk (DATA-001: chunking strategy) could directly cause the spike to fail its 70% accuracy threshold. This must be addressed during implementation.

---

## Critical Risks Requiring Immediate Attention

### 1. DATA-001: Simple Chunking Loses Table Context

**Score: 9 (Critical)**
**Probability:** High (3) - Word-based chunking (500 words, 50 overlap) will inevitably split financial tables
**Impact:** High (3) - Could cause retrieval accuracy to fall below 70% GO threshold, triggering NO-GO decision

**Why This Matters:**
Financial documents contain critical data in tabular format (revenue, expenses, forecasts). Simple word-based chunking will split rows mid-table, destroying semantic meaning. When a query asks "What was Q3 revenue?", the system may retrieve a chunk containing only column headers or partial rows.

**Mitigation:**
1. **Implement table-aware chunking** - Preserve complete tables within single chunks when possible
2. **Add table metadata** - Include table titles, column headers in chunk metadata
3. **Test on table-heavy queries** - Ensure 5+ of the 15 ground truth queries specifically target tabular data
4. **Monitor table extraction quality** - Manually verify Docling preserves table structure during extraction
5. **Fallback strategy** - If accuracy fails due to tables, consider semantic chunking or GraphRAG approach from architecture docs

**Testing Focus:**
- Create test queries specifically targeting financial tables (e.g., "What was total revenue in Q2?")
- Verify retrieved chunks contain complete table rows, not fragments
- Validate that table context (headers, row labels) is preserved
- Test edge cases: multi-page tables, merged cells, nested tables

**Residual Risk:** Medium - Even with table-aware chunking, very large tables may still require splitting

**Owner:** Dev
**Timeline:** During Task 3 (Document Chunking) - BEFORE generating embeddings

---

## High-Priority Risks

### 2. TECH-001: Docling Extraction Failure on Complex Tables

**Score: 6 (High)**
**Probability:** Medium (2) - While Docling has 97.9% accuracy benchmark, this is a NEW 100+ page PDF
**Impact:** High (3) - Would invalidate Docling choice, force technology stack pivot

**Mitigation:**
- Manually spot-check extracted tables against source PDF (Task 2)
- Verify complex table features: merged cells, multi-line headers, nested structures
- Document any extraction failures with page numbers and table types
- If failures >10% of tables, consider AWS Textract fallback (mentioned in architecture)

**Testing Focus:** Manual validation of 10+ representative tables from test PDF

---

### 3. TECH-003: Version Conflicts Between Dependencies

**Score: 6 (High)**
**Probability:** High (3) - Multiple libraries: Docling, Fin-E5, FastMCP, Qdrant client
**Impact:** Medium (2) - Could consume 1-2 days of the 3-5 day spike timeline

**Mitigation:**
- Use virtual environment with pinned versions
- Document all dependency versions in requirements.txt
- Test installation on fresh environment before starting implementation
- Maintain fallback versions if conflicts arise

**Testing Focus:** Clean install test on fresh Python 3.11 environment

---

### 4. TECH-004: FastMCP Protocol Integration Complexity

**Score: 6 (High)**
**Probability:** Medium (2) - Novel technology, first-time integration with MCP protocol
**Impact:** High (3) - Core requirement for MCP server deliverable

**Mitigation:**
- Start with minimal FastMCP example from documentation
- Test tool discovery endpoint independently before implementing query logic
- Use FastMCP 1.x official SDK (19k GitHub stars, well-documented)
- Allocate full day (Day 4) for MCP server implementation
- If blocked >4 hours, consult FastMCP examples/community

**Testing Focus:** Tool discovery, query tool invocation, response format validation

---

### 5. BUS-001: Retrieval Accuracy Below 70% GO Threshold

**Score: 6 (High)**
**Probability:** Medium (2) - New tech stack, untested on this specific financial domain
**Impact:** High (3) - Triggers REASSESS or NO-GO decision, blocks Phase 1

**Mitigation:**
- Create diverse ground truth queries covering: tables, narrative text, calculations, forecasts
- Test queries progressively as chunks are indexed (don't wait until end)
- If accuracy 50-69%, analyze failure modes: chunking issues? embedding quality? retrieval parameters?
- Document which query types succeed/fail for Phase 1 improvements
- Have contingency plan: Voyage-3-large embeddings (74.63% accuracy) as fallback

**Testing Focus:** Comprehensive 15 Q&A test set with varied query types

---

## Medium-Priority Risks

### 6. TECH-002: Fin-E5 Model Initialization/Download Failures

**Score: 4 (Medium)**
**Probability:** Medium (2) | **Impact:** Medium (2)

**Mitigation:** Verify model download before starting embedding generation, test on small sample first

---

### 7. SEC-001: Sensitive Data in Test PDF Committed to Repository

**Score: 4 (Medium)**
**Probability:** Medium (2) | **Impact:** Medium (2)

**Mitigation:** Add `/Users/ricardocarvalho/DeveloperFolder/RAGLite/docs/sample pdf` to .gitignore, verify before any commits

---

### 8. PERF-001: PDF Ingestion Exceeds 5-Minute NFR Target

**Score: 4 (Medium)**
**Probability:** Medium (2) | **Impact:** Medium (2)

**Mitigation:** Log ingestion time (Task 2), if >5 min investigate Docling configuration or batch processing

---

### 9. PERF-002: Embedding Generation Takes Too Long

**Score: 4 (Medium)**
**Probability:** Medium (2) | **Impact:** Medium (2)

**Mitigation:** Implement batch processing (Task 4), monitor GPU usage if available, log generation time

---

### 10. BUS-002: Spike Exceeds 3-5 Day Timeline

**Score: 4 (Medium)**
**Probability:** Medium (2) | **Impact:** Medium (2)

**Mitigation:** Follow recommended day-by-day approach in Dev Notes, flag blockers early, timeboxing (max 4 hours per blocker)

---

### 11. OPS-001: Incomplete Integration Issues Documentation

**Score: 4 (Medium)**
**Probability:** Medium (2) | **Impact:** Medium (2)

**Mitigation:** Maintain running notes during spike, dedicate Day 5 to documentation, use Week 0 Spike Report template

---

## Low-Priority Risks

### 12. BUS-003: Ground Truth Q&A Pairs Not Representative

**Score: 3 (Low)**
**Probability:** Low (1) | **Impact:** High (3)

**Mitigation:** Review Q&A pairs with domain expert, ensure coverage of tables, narratives, calculations

---

### 13. SEC-002: Qdrant Exposed Without Authentication

**Score: 3 (Low)**
**Probability:** High (3) | **Impact:** Low (1)

**Mitigation:** Acceptable for local spike, document need for auth in Phase 1

---

### 14. OPS-002: Spike Code Accidentally Used in Phase 1

**Score: 3 (Low)**
**Probability:** Low (1) | **Impact:** High (3)

**Mitigation:** Clear directory separation (raglite-spike/ vs raglite/), document in Week 0 report

---

### 15. PERF-003: Query Latency Exceeds 5-Second Target

**Score: 2 (Low)**
**Probability:** Low (1) | **Impact:** Medium (2)

**Mitigation:** Use Qdrant HNSW indexing (default), measure p50/p95 latency

---

### 16. DATA-002: Metadata Loss During Ingestion

**Score: 2 (Low)**
**Probability:** Low (1) | **Impact:** Medium (2)

**Mitigation:** Verify metadata fields (source, page, section) in Qdrant after storage

---

### 17. TECH-005: Qdrant Docker Networking Issues on macOS

**Score: 1 (Minimal)**
**Probability:** Low (1) | **Impact:** Low (1)

**Mitigation:** Use Docker Compose health checks, verify Qdrant API accessibility

---

## Risk Distribution

### By Category

| Category | Total Risks | Critical | High | Medium | Low |
|----------|-------------|----------|------|--------|-----|
| Technical (TECH) | 5 | 0 | 2 | 1 | 2 |
| Security (SEC) | 2 | 0 | 0 | 1 | 1 |
| Performance (PERF) | 3 | 0 | 0 | 2 | 1 |
| Data (DATA) | 2 | 1 | 0 | 0 | 1 |
| Business (BUS) | 3 | 0 | 1 | 1 | 1 |
| Operational (OPS) | 2 | 0 | 0 | 1 | 1 |

### By Component

| Component | Risk Count | Highest Risk |
|-----------|------------|--------------|
| Document Chunking | 2 | DATA-001 (Critical) |
| PDF Extraction (Docling) | 1 | TECH-001 (High) |
| Embeddings (Fin-E5) | 1 | TECH-002 (Medium) |
| Vector Store (Qdrant) | 2 | TECH-005 (Low) |
| MCP Server (FastMCP) | 1 | TECH-004 (High) |
| Accuracy Validation | 2 | BUS-001 (High) |
| Integration | 1 | TECH-003 (High) |
| Operations | 2 | OPS-001 (Medium) |
| Security | 2 | SEC-001 (Medium) |
| Performance | 3 | PERF-001 (Medium) |

---

## Detailed Risk Register

| Risk ID | Category | Description | Probability | Impact | Score | Priority |
|---------|----------|-------------|-------------|--------|-------|----------|
| DATA-001 | Data | Simple chunking loses table context | High (3) | High (3) | 9 | Critical |
| TECH-001 | Technical | Docling extraction failure on complex tables | Medium (2) | High (3) | 6 | High |
| TECH-003 | Technical | Version conflicts between dependencies | High (3) | Medium (2) | 6 | High |
| TECH-004 | Technical | FastMCP protocol integration complexity | Medium (2) | High (3) | 6 | High |
| BUS-001 | Business | Retrieval accuracy below 70% threshold | Medium (2) | High (3) | 6 | High |
| TECH-002 | Technical | Fin-E5 model initialization failures | Medium (2) | Medium (2) | 4 | Medium |
| SEC-001 | Security | Sensitive data in test PDF committed to repo | Medium (2) | Medium (2) | 4 | Medium |
| PERF-001 | Performance | PDF ingestion exceeds 5-minute target | Medium (2) | Medium (2) | 4 | Medium |
| PERF-002 | Performance | Embedding generation takes too long | Medium (2) | Medium (2) | 4 | Medium |
| BUS-002 | Business | Spike exceeds 3-5 day timeline | Medium (2) | Medium (2) | 4 | Medium |
| OPS-001 | Operational | Incomplete integration issues documentation | Medium (2) | Medium (2) | 4 | Medium |
| BUS-003 | Business | Ground truth Q&A pairs not representative | Low (1) | High (3) | 3 | Low |
| SEC-002 | Security | Qdrant exposed without authentication | High (3) | Low (1) | 3 | Low |
| OPS-002 | Operational | Spike code accidentally used in Phase 1 | Low (1) | High (3) | 3 | Low |
| PERF-003 | Performance | Query latency exceeds 5-second target | Low (1) | Medium (2) | 2 | Low |
| DATA-002 | Data | Metadata loss during ingestion | Low (1) | Medium (2) | 2 | Low |
| TECH-005 | Technical | Qdrant Docker networking issues on macOS | Low (1) | Low (1) | 1 | Minimal |

---

## Risk-Based Testing Strategy

### Priority 1: Critical Risk Tests (MUST COMPLETE)

**Focus: DATA-001 - Table Context Preservation**

1. **Table Extraction Validation**
   - Test Case: Extract financial tables from test PDF
   - Verify: Complete table structure preserved (headers, rows, columns)
   - Success Criteria: 95%+ of tables extracted correctly

2. **Table-Aware Chunking Tests**
   - Test Case: Chunk document containing multi-row financial tables
   - Verify: Tables not split mid-row, headers included with data
   - Success Criteria: No table fragmentation in retrieved chunks

3. **Table-Specific Retrieval Tests**
   - Test Case: Query "What was Q3 revenue?" against chunked data
   - Verify: Retrieved chunk contains complete revenue table or relevant row
   - Success Criteria: 5+ table-focused queries succeed (out of 15 total)

**Required Test Data:**
- 15 ground truth Q&A pairs with at least 5 targeting tabular data
- Sample queries: revenue figures, expense breakdowns, financial ratios from tables

---

### Priority 2: High Risk Tests

**TECH-001: Docling Extraction Quality**
- Manual spot-check: 10+ representative tables (simple, complex, merged cells)
- Validation: Compare extracted text/tables against source PDF
- Document: Any extraction failures with page numbers

**TECH-003: Dependency Integration**
- Clean install test on fresh Python 3.11 virtual environment
- Version compatibility verification
- Requirements.txt freeze after successful installation

**TECH-004: FastMCP Server**
- Tool discovery endpoint test
- Query tool invocation with sample input
- Response format validation (returns chunks with metadata)

**BUS-001: Accuracy Threshold**
- Run all 15 test queries through complete pipeline
- Calculate accuracy: (successful queries / 15) × 100%
- Analyze failure modes if accuracy <70%

---

### Priority 3: Medium/Low Risk Tests

**Performance Baselines:**
- Ingestion time measurement (target: <5 minutes)
- Embedding generation time per chunk
- Query latency (p50, p95) - target: <5 seconds

**Operational Validation:**
- Qdrant container health check
- Docker Compose networking verification
- Metadata preservation check (source, page, section)

---

## Risk Acceptance Criteria

### Must Fix Before Completing Spike

1. **DATA-001 (Critical):** Implement table-aware chunking or document workaround
2. **TECH-003 (High):** Resolve all dependency conflicts
3. **TECH-004 (High):** Achieve functional FastMCP server with query tool
4. **BUS-001 (High):** Measure accuracy baseline (even if <70%, must measure and document)

### Can Complete Spike With Mitigation

1. **TECH-001:** If minor extraction issues, document for Phase 1
2. **Performance risks (PERF-001, PERF-002):** Measure baselines, document if targets missed
3. **SEC-001:** Ensure .gitignore prevents commit, acceptable for spike
4. **BUS-002:** Up to 7 days acceptable if critical learnings achieved

### Accepted Risks for Spike

1. **SEC-002:** Qdrant without auth acceptable for local development
2. **OPS-002:** Clear documentation sufficient to prevent confusion
3. **Low-priority risks:** Monitor but don't block spike completion

---

## Monitoring Requirements

### During Spike Implementation

**Daily Progress Checks:**
- Day 1-2: Docling extraction quality, dependency installation success
- Day 3: Qdrant connectivity, vector storage verification
- Day 4: FastMCP server functionality, ground truth creation
- Day 5: Accuracy measurement, performance baselines, documentation

**Blocker Escalation:**
- If any task blocked >4 hours: Document issue, research alternatives
- If accuracy trend shows <50%: Immediate root cause analysis
- If timeline slips >2 days: Reassess scope, consider simplified deliverables

---

### Post-Spike Validation

**Week 0 Spike Report Must Include:**
- Accuracy results: X/15 queries successful (Y% accuracy)
- Performance baselines: ingestion time, embedding time, query latency
- All integration issues encountered and resolutions
- Technology validation: Did each component work as expected?
- GO/NO-GO recommendation with evidence

**Phase 1 Handoff:**
- Document all risks encountered during spike
- Update risk profile for Phase 1 Week 1 based on learnings
- Flag any residual risks requiring attention

---

## Risk Review Triggers

**Review and update this risk profile when:**

1. **Accuracy threshold not met:** If initial tests show <70%, analyze root cause and update risk assessment
2. **Technology blocker discovered:** If Docling, Fin-E5, FastMCP, or Qdrant has major issue
3. **Timeline slip:** If spike exceeds 5 days, reassess remaining risks
4. **Scope change:** If acceptance criteria modified based on findings

---

## Integration with Quality Gates

**Deterministic Gate Mapping:**

- **Any risk score ≥ 9:** Gate = CONCERNS (Critical risk present)
- **Else if any score ≥ 6:** Gate = CONCERNS (High risks require mitigation)
- **Else:** Gate = PASS

**Current Assessment:**
- 1 Critical risk (DATA-001: score 9)
- 4 High risks (TECH-001, TECH-003, TECH-004, BUS-001: score 6)

**Expected Gate Decision:** CONCERNS (until DATA-001 mitigated during implementation)

---

## Recommendations for Story Implementation

### Immediate Actions (Before Starting)

1. ✅ **Add test PDF to .gitignore** - Prevent SEC-001
2. ✅ **Set up clean Python 3.11 virtual environment** - Mitigate TECH-003
3. ✅ **Review Docling table extraction documentation** - Prepare for DATA-001

### During Implementation

1. **Task 3 (Chunking):** Implement table-aware chunking strategy - **CRITICAL**
2. **Task 7 (Ground Truth):** Create 5+ table-focused queries - **HIGH PRIORITY**
3. **Task 8 (Accuracy):** Test table queries first to validate DATA-001 mitigation
4. **All tasks:** Maintain running notes of integration issues (OPS-001)

### Before Completing Spike

1. **Verify all 4 high-risk mitigations** completed or documented
2. **Measure accuracy baseline** even if <70% (required for GO/NO-GO)
3. **Complete Week 0 Spike Report** with all findings
4. **Make evidence-based GO/NO-GO recommendation**

---

## Risk Profile Summary for Gate File

```yaml
risk_summary:
  totals:
    critical: 1  # score 9
    high: 4      # score 6
    medium: 6    # score 4
    low: 4       # score 2-3
  highest:
    id: DATA-001
    score: 9
    title: 'Simple chunking loses table context'
  recommendations:
    must_fix:
      - 'Implement table-aware chunking to preserve financial table context (DATA-001)'
      - 'Resolve dependency version conflicts before starting implementation (TECH-003)'
      - 'Achieve functional FastMCP server with query tool (TECH-004)'
    monitor:
      - 'Validate Docling table extraction quality on test PDF (TECH-001)'
      - 'Track accuracy baseline against 70% GO threshold (BUS-001)'
      - 'Measure performance baselines: ingestion, embedding, query latency'
      - 'Document all integration issues for Phase 1 (OPS-001)'
```

---

**Report Generated:** 2025-10-03
**Next Review:** After spike completion (Day 5) or if accuracy <70% detected
**Artifact Location:** `docs/qa/assessments/0.1-week-0-integration-spike-risk-20251003.md`
