# Test Design: Story 0.1 - Week 0 Integration Spike

**Date:** 2025-10-03
**Designer:** Quinn (Test Architect)
**Story:** Week 0 Integration Spike
**Type:** Integration Spike (Throwaway Prototype)

---

## Executive Summary

This test design focuses on validating the **end-to-end technology stack integration** for the RAGLite project. As a critical spike that blocks all Phase 1 work, the test strategy emphasizes integration and E2E validation over unit testing, with primary focus on the **GO/NO-GO decision criteria** (â‰¥70% retrieval accuracy).

**Key Insight:** This spike IS the test. The entire story validates technology feasibility before production development begins.

---

## Test Strategy Overview

- **Total test scenarios:** 23
- **Integration tests:** 12 (52%)
- **E2E tests:** 8 (35%)
- **Manual validation:** 3 (13%)
- **Priority distribution:** P0: 5, P1: 10, P2: 5, P3: 3

### Test Philosophy for Spike

Given this is a **throwaway prototype**, the test strategy is pragmatic:

- âœ… **Focus on integration validation** - Components must work together
- âœ… **Measure success criteria** - Accuracy â‰¥70%, latency <5s
- âœ… **Document issues** - Critical for Phase 1 planning
- âŒ **Minimal unit testing** - Not production code, using libraries as-is
- âŒ **No extensive error handling** - Quick validation over robustness

---

## Test Scenarios by Acceptance Criteria

### AC1: Ingest 1 Real Company Financial PDF (100+ pages) with Docling

#### Test Scenarios

| ID          | Level       | Priority | Test                                    | Justification                                          | Risk Mitigation |
| ----------- | ----------- | -------- | --------------------------------------- | ------------------------------------------------------ | --------------- |
| 0.1-INT-001 | Integration | P1       | Docling successfully ingests 100+ page PDF | Validates core Docling library integration             | RISK-001        |
| 0.1-INT-002 | Integration | P1       | Table structure extracted correctly     | Financial PDFs are table-heavy; critical for accuracy  | RISK-002        |
| 0.1-INT-003 | Integration | P2       | Text content extracted without corruption | Validates baseline extraction quality                  | RISK-002        |

**Coverage:** Basic ingestion validation with focus on table extraction (97.9% expected accuracy per research).

---

### AC2: Generate Embeddings with Fin-E5 Model

#### Test Scenarios

| ID          | Level       | Priority | Test                                    | Justification                                          | Risk Mitigation |
| ----------- | ----------- | -------- | --------------------------------------- | ------------------------------------------------------ | --------------- |
| 0.1-INT-004 | Integration | P1       | Fin-E5 generates embeddings for all chunks | Validates model integration and batch processing       | RISK-001        |
| 0.1-INT-005 | Integration | P2       | Embedding dimensions match expected     | Validates model output matches Qdrant configuration    | RISK-001        |

**Coverage:** Core embedding generation with dimension validation.

---

### AC3: Store Vectors in Qdrant via Docker Compose

#### Test Scenarios

| ID          | Level       | Priority | Test                                    | Justification                                          | Risk Mitigation |
| ----------- | ----------- | -------- | --------------------------------------- | ------------------------------------------------------ | --------------- |
| 0.1-INT-006 | Integration | P2       | Qdrant container starts via Docker Compose | Validates deployment environment setup                 | RISK-001        |
| 0.1-INT-007 | Integration | P1       | Collection created with correct configuration | Critical for vector storage; wrong config blocks search | RISK-001        |
| 0.1-INT-008 | Integration | P0       | Vectors stored with metadata            | Core functionality; without storage, no retrieval      | RISK-001        |
| 0.1-INT-009 | Integration | P0       | Vector retrieval works (basic search)   | Validates Qdrant can return stored vectors             | RISK-001        |

**Coverage:** Full Qdrant integration including storage and basic retrieval.

---

### AC4: Implement Basic MCP Server (FastMCP) Exposing Query Tool

#### Test Scenarios

| ID          | Level       | Priority | Test                                    | Justification                                          | Risk Mitigation |
| ----------- | ----------- | -------- | --------------------------------------- | ------------------------------------------------------ | --------------- |
| 0.1-INT-010 | Integration | P2       | FastMCP server starts successfully      | Basic smoke test for server initialization             | RISK-001        |
| 0.1-INT-011 | Integration | P1       | MCP tool discovery protocol responds    | Validates MCP protocol compliance                      | RISK-001        |
| 0.1-INT-012 | Integration | P0       | Query tool returns search results       | Core functionality; needed for accuracy measurement    | RISK-001        |

**Coverage:** MCP server integration with protocol compliance validation.

---

### AC5: Create 15 Ground Truth Q&A Pairs from Test Document

#### Test Scenarios

| ID             | Level  | Priority | Test                                    | Justification                                          | Risk Mitigation |
| -------------- | ------ | -------- | --------------------------------------- | ------------------------------------------------------ | --------------- |
| 0.1-MANUAL-001 | Manual | P0       | 15 Q&A pairs created from test PDF     | Required for accuracy measurement; no automation possible | RISK-002        |
| 0.1-MANUAL-002 | Manual | P1       | Questions cover diverse financial topics | Ensures representative test set (revenue, expenses, forecasts, tables) | RISK-002        |

**Coverage:** Manual creation of ground truth test set. Each pair must include: `{question, expected_answer, source_page}`.

**Quality Requirements:**
- Queries span different document sections
- Mix of simple facts and complex table queries
- Include both text-based and numerical answers
- Document expected answers with page references

---

### AC6: Measure Baseline Retrieval Accuracy (Vector Search Only)

#### Test Scenarios - **CRITICAL GO/NO-GO TESTS**

| ID          | Level | Priority | Test                                    | Justification                                          | Risk Mitigation |
| ----------- | ----- | -------- | --------------------------------------- | ------------------------------------------------------ | --------------- |
| 0.1-E2E-001 | E2E   | P0       | Complete pipeline processes all 15 queries | **GO/NO-GO CRITICAL**: Validates end-to-end integration works | RISK-001, RISK-002 |
| 0.1-E2E-002 | E2E   | P0       | Accuracy calculation (â‰¥70% threshold)   | **GO/NO-GO CRITICAL**: Determines if technology stack is viable | RISK-002        |
| 0.1-E2E-003 | E2E   | P1       | Document failure modes for failed queries | Critical for understanding weaknesses and Phase 1 planning | RISK-002        |
| 0.1-E2E-004 | E2E   | P0       | Validate full integration (PDFâ†’Doclingâ†’Fin-E5â†’Qdrantâ†’FastMCP) | **GO/NO-GO CRITICAL**: All components must work together | RISK-001        |

**Success Criteria:**
- âœ… **GO (â‰¥70%):** 10+ out of 15 queries return relevant chunks â†’ Proceed to Phase 1
- âš ï¸ **REASSESS (50-69%):** 8-9 out of 15 queries succeed â†’ Debug before Phase 1
- ðŸ›‘ **NO-GO (<50%):** <8 queries succeed â†’ Reconsider technology stack

**Evaluation Process:**
1. Run each of 15 queries through MCP server
2. Receive top-5 chunks per query
3. Manually verify if ANY chunk contains information to answer query
4. Mark as âœ… (accurate) or âŒ (inaccurate)
5. Calculate: (âœ… count / 15) Ã— 100%
6. Document why each failed query failed (chunking issue? embedding issue? search issue?)

---

### AC7: Document Integration Issues, API Quirks, Version Conflicts

#### Test Scenarios

| ID             | Level  | Priority | Test                                    | Justification                                          | Risk Mitigation |
| -------------- | ------ | -------- | --------------------------------------- | ------------------------------------------------------ | --------------- |
| 0.1-MANUAL-003 | Manual | P1       | Document all integration issues encountered | Critical for Phase 1 risk mitigation and planning      | RISK-001        |

**Documentation Requirements:**
- API quirks or unexpected behaviors
- Version conflicts or dependency issues
- Workarounds or configuration adjustments needed
- Potential risks for Phase 1

---

### AC8: Establish Performance Baseline (Ingestion Time, Query Latency)

#### Test Scenarios

| ID          | Level | Priority | Test                                    | Justification                                          | Risk Mitigation |
| ----------- | ----- | -------- | --------------------------------------- | ------------------------------------------------------ | --------------- |
| 0.1-E2E-005 | E2E   | P1       | Measure PDF ingestion time (<5 min target) | Validates NFR2 from PRD (5 min for 100-page PDF)       | -               |
| 0.1-E2E-006 | E2E   | P1       | Measure embedding generation time       | Establishes baseline for optimization planning         | -               |
| 0.1-E2E-007 | E2E   | P0       | Measure query latency p50 (<5s target) | **CRITICAL**: Validates architecture requirement (sub-5 second retrieval) | -               |
| 0.1-E2E-008 | E2E   | P1       | Measure query latency p95              | Identifies worst-case performance                      | -               |

**Performance Targets:**
- **Ingestion:** <5 minutes for 100-page PDF (NFR2)
- **Query latency (p50):** <5 seconds (architecture requirement)
- **Query latency (p95):** Document for baseline

**Measurement Process:**
1. Record start/end timestamps for each operation
2. Calculate elapsed time
3. For query latency: Run all 15 queries, calculate p50 and p95
4. Document all metrics in Week 0 Spike Report

---

## Risk Coverage

This test design directly addresses the following risks from the PRD:

- **RISK-001: High probability of integration failures with novel technology stack**
  - Mitigated by: 12 integration tests + 8 E2E tests validating complete pipeline
  - Focus: Early detection of incompatibilities

- **RISK-002: Accuracy shortfalls may require technology pivots**
  - Mitigated by: AC6 accuracy measurement with clear GO/NO-GO thresholds (70%)
  - Focus: Validate Docling + Fin-E5 + Qdrant can achieve acceptable retrieval accuracy

**Testing enables cheap pivoting:** If spike fails, alternative technologies can be explored without wasting 5 weeks of Phase 1 development.

---

## Test Execution Strategy

### Recommended Execution Order

**Phase 1: Component Integration (Day 1-3)**
1. P2 Integration tests (basic smoke tests)
   - 0.1-INT-006: Qdrant starts
   - 0.1-INT-010: FastMCP server starts
2. P1 Integration tests (core functionality)
   - 0.1-INT-001 through 0.1-INT-005: Docling, Fin-E5
   - 0.1-INT-007, 0.1-INT-011: Qdrant collection, MCP protocol
3. P0 Integration tests (critical path)
   - 0.1-INT-008, 0.1-INT-009: Vector storage/retrieval
   - 0.1-INT-012: Query tool functionality

**Phase 2: Ground Truth Creation (Day 4)**
4. P0 Manual validation
   - 0.1-MANUAL-001: Create 15 Q&A pairs
5. P1 Manual validation
   - 0.1-MANUAL-002: Validate question diversity

**Phase 3: Critical E2E Validation (Day 4-5)**
6. **P0 E2E tests (GO/NO-GO decision)**
   - 0.1-E2E-004: Validate full pipeline integration
   - 0.1-E2E-001: Process all 15 queries
   - 0.1-E2E-002: **Calculate accuracy (â‰¥70% threshold)**
   - 0.1-E2E-007: Query latency p50 (<5s)

**Phase 4: Baseline Measurement & Documentation (Day 5)**
7. P1 E2E tests (performance baselines)
   - 0.1-E2E-005: Ingestion time
   - 0.1-E2E-006: Embedding time
   - 0.1-E2E-008: Query latency p95
8. P1 E2E documentation
   - 0.1-E2E-003: Document failure modes
9. P1 Manual documentation
   - 0.1-MANUAL-003: Document integration issues

### Fail-Fast Strategy

- **STOP immediately if:**
  - 0.1-E2E-002 shows accuracy <50% â†’ Technology stack unsuitable
  - 0.1-E2E-007 shows query latency >10s â†’ Performance unacceptable
  - 0.1-E2E-004 reveals major integration blockers requiring >2 days to fix

- **Reassess if:**
  - Accuracy 50-69% â†’ Debug before final GO/NO-GO decision
  - Query latency 5-10s â†’ Investigate optimization opportunities

---

## Test Coverage Summary

### Coverage by Acceptance Criteria

| AC  | Description                      | Test Count | P0 | P1 | P2+ | Coverage Level |
| --- | -------------------------------- | ---------- | -- | -- | --- | -------------- |
| AC1 | Docling PDF ingestion            | 3          | 0  | 2  | 1   | âœ… Adequate     |
| AC2 | Fin-E5 embeddings                | 2          | 0  | 1  | 1   | âœ… Adequate     |
| AC3 | Qdrant vector storage            | 4          | 2  | 1  | 1   | âœ… Comprehensive |
| AC4 | FastMCP server                   | 3          | 1  | 1  | 1   | âœ… Adequate     |
| AC5 | Ground truth Q&A creation        | 2          | 1  | 1  | 0   | âœ… Adequate     |
| AC6 | **Accuracy measurement**         | **4**      | **3** | **1** | **0** | âœ… **Critical** |
| AC7 | Integration issues documentation | 1          | 0  | 1  | 0   | âœ… Adequate     |
| AC8 | Performance baselines            | 4          | 1  | 3  | 0   | âœ… Comprehensive |

### Coverage Gaps

**None identified.** All acceptance criteria have appropriate test coverage for a spike/prototype.

### Test Level Distribution Rationale

- **52% Integration tests:** Appropriate for validating component integration (Docling, Fin-E5, Qdrant, FastMCP)
- **35% E2E tests:** Focuses on critical success criteria (accuracy, performance, full pipeline)
- **13% Manual validation:** Necessary for test data creation and issue documentation
- **0% Unit tests:** Justified for throwaway prototype using external libraries

---

## Quality Checklist

Before finalizing test execution, verify:

- [x] Every AC has test coverage
- [x] Test levels are appropriate (not over-testing throwaway code)
- [x] No duplicate coverage across levels
- [x] Priorities align with GO/NO-GO business risk
- [x] Test IDs follow naming convention (0.1-{LEVEL}-{SEQ})
- [x] Scenarios are atomic and independent
- [x] P0 tests map to critical success criteria

---

## Key Testing Principles Applied

1. **Shift left (pragmatically):** Integration tests for library validation, E2E for success criteria
2. **Risk-based:** P0 tests focus on GO/NO-GO decision (accuracy â‰¥70%, latency <5s)
3. **Efficient coverage:** Test once at the right level (no redundant unit tests for spike)
4. **Maintainability:** Simple test structure for throwaway code
5. **Fast feedback:** Integration tests run first to catch blockers early

---

## Deliverable Integration

This test design supports the **Week 0 Spike Report** deliverable by providing:

1. **Accuracy Results:** 0.1-E2E-001, 0.1-E2E-002 (X out of 15 queries successful = Y% accuracy)
2. **Performance Baselines:** 0.1-E2E-005 through 0.1-E2E-008
3. **Integration Issues:** 0.1-MANUAL-003 documentation
4. **GO/NO-GO Recommendation:** Based on 0.1-E2E-002 results against thresholds

---

## Notes for Test Implementation

### Test Data Location
- **Test PDF:** `/Users/ricardocarvalho/DeveloperFolder/RAGLite/docs/sample pdf`
- **Ground Truth:** `tests/ground_truth.json` (to be created in 0.1-MANUAL-001)

### Test Framework
- **Framework:** pytest + pytest-asyncio
- **Approach:** Manual validation acceptable for spike (automated testing deferred to Phase 1)
- **Focus:** End-to-end validation over unit testing

### Known Limitations (Expected for Spike)
- âŒ No LLM synthesis testing (vector search only)
- âŒ No Excel support testing (PDF only)
- âŒ No Contextual Retrieval testing (basic chunking)
- âŒ Minimal error handling validation
- âŒ No CI/CD testing (local execution only)

**Rationale:** Focus on core integration validation before investing in production features.

---

## Appendix: Test Scenario Quick Reference

### All Test Scenarios (Alphabetical by ID)

| ID             | Level       | Priority | AC  | Test Description                                    |
| -------------- | ----------- | -------- | --- | --------------------------------------------------- |
| 0.1-E2E-001    | E2E         | P0       | AC6 | Complete pipeline processes all 15 queries          |
| 0.1-E2E-002    | E2E         | P0       | AC6 | Accuracy calculation (â‰¥70% threshold) **GO/NO-GO**  |
| 0.1-E2E-003    | E2E         | P1       | AC6 | Document failure modes for failed queries           |
| 0.1-E2E-004    | E2E         | P0       | AC6 | Validate full integration (PDFâ†’Doclingâ†’Fin-E5â†’Qdrantâ†’FastMCP) |
| 0.1-E2E-005    | E2E         | P1       | AC8 | Measure PDF ingestion time (<5 min target)          |
| 0.1-E2E-006    | E2E         | P1       | AC8 | Measure embedding generation time                   |
| 0.1-E2E-007    | E2E         | P0       | AC8 | Measure query latency p50 (<5s target) **CRITICAL** |
| 0.1-E2E-008    | E2E         | P1       | AC8 | Measure query latency p95                           |
| 0.1-INT-001    | Integration | P1       | AC1 | Docling successfully ingests 100+ page PDF          |
| 0.1-INT-002    | Integration | P1       | AC1 | Table structure extracted correctly                 |
| 0.1-INT-003    | Integration | P2       | AC1 | Text content extracted without corruption           |
| 0.1-INT-004    | Integration | P1       | AC2 | Fin-E5 generates embeddings for all chunks          |
| 0.1-INT-005    | Integration | P2       | AC2 | Embedding dimensions match expected                 |
| 0.1-INT-006    | Integration | P2       | AC3 | Qdrant container starts via Docker Compose          |
| 0.1-INT-007    | Integration | P1       | AC3 | Collection created with correct configuration       |
| 0.1-INT-008    | Integration | P0       | AC3 | Vectors stored with metadata                        |
| 0.1-INT-009    | Integration | P0       | AC3 | Vector retrieval works (basic search)               |
| 0.1-INT-010    | Integration | P2       | AC4 | FastMCP server starts successfully                  |
| 0.1-INT-011    | Integration | P1       | AC4 | MCP tool discovery protocol responds                |
| 0.1-INT-012    | Integration | P0       | AC4 | Query tool returns search results                   |
| 0.1-MANUAL-001 | Manual      | P0       | AC5 | 15 Q&A pairs created from test PDF                  |
| 0.1-MANUAL-002 | Manual      | P1       | AC5 | Questions cover diverse financial topics            |
| 0.1-MANUAL-003 | Manual      | P1       | AC7 | Document all integration issues encountered         |

---

**Test Design Complete**
**Ready for implementation during Week 0 Integration Spike**
